{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author : Pavan Yekabote\n",
    "# Perceptron algorithm using gradient descent for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Perceptron:\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "        self.trained = False\n",
    "        pass\n",
    "    \n",
    "    def sigmoid(self,x, derive=False):\n",
    "        # Check if x is type of array or list\n",
    "        if type(x) ==np.ndarray or type(x) == list:\n",
    "            # Convert list to numpy array\n",
    "            x = np.array(x) if type(x) == list else x\n",
    "            # if shape is more than one dimension, then throw error\n",
    "            if len(x.shape) > 1:\n",
    "                return \"Dimension Error\"\n",
    "            # return sigmoid array\n",
    "            return np.array([self.sigmoid(i) if not derive else self.sigmoid(i, derive=True) for i in x])\n",
    "\n",
    "        if not derive:\n",
    "            return 1/(1+np.exp(-x))\n",
    "        else:\n",
    "            y = self.sigmoid(x)\n",
    "            return y * (1 - y)\n",
    "        \n",
    "    def train(self,X,y,max_iter=100, lr=0.8):\n",
    "        self.W = np.random.randn((X.shape[1]))\n",
    "        self.bias = 1\n",
    "        y = np.array(y).flatten()\n",
    "        \n",
    "        for iteration in range(max_iter):\n",
    "           \n",
    "            for i,x in enumerate(X):\n",
    "                y_hat = self.predict(x)\n",
    "\n",
    "            # using mean_squared_error [(y-y_hat) power 2 ] as loss function\n",
    "            # Calculation of gradient\n",
    "            # Prediction = y_hat = sigmoid(Weights=W * inputs = x +b )\n",
    "            # Since Error in output ( Mean Squared Error ) E = ( y_actual - y_hat ) power 2.\n",
    "            # Therefore change in Error E w.r.t Weights W = dE/dW\n",
    "            # As y_hat = sigmoid(Wx+b) \n",
    "            # => d/dW( sigmoid(Wx+b) ) = sigmoid(Wx+b) * (1- sigmoid(Wx+b)) * d/dW(Wx+b)\n",
    "            # => d/dW( sigmoid(Wx+b) ) = sigmoid(Wx+b) * (1- sigmoid(Wx+b)) * x        [ Since d/dW (Wx+b) = x]\n",
    "            # dE/dw=[d ( (y-y_hat) power 2 ) / dW ]= 2 ( y-y_hat ) * sigmoid(y-y_hat) * (1-sigmoid(y-y_hat)) * x\n",
    "            # Hence take this small change dE/dW and add to the Weights to get prediction y_hat near to y\n",
    "            # And we multiply a learning rate to let the gradient be descended taking small steps\n",
    "                \n",
    "                gradient = 2 * (y[i]-y_hat) * lr * self.sigmoid(y_hat, derive=True)\n",
    "                \n",
    "                # Applying gradient descent and updating weights\n",
    "                self.W += np.multiply(gradient , x)\n",
    "                # Update bias with the gradient\n",
    "                self.bias += gradient \n",
    "                \n",
    "        return (self.W, self.bias)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def predict(self,x):\n",
    "        if self.W is None:\n",
    "            return \"Train model before use\"\n",
    "        if len(x.shape) > 1 and len(x[0].shape)==1:\n",
    "             return np.round(np.array([self.predict(i) for i in x]).flatten(), decimals=3)\n",
    "        return self.sigmoid(np.matmul(self.W, x.flatten()).flatten()+self.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_and = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.int16)\n",
    "y_and = np.array([[0],[0],[0],[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_and = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.012, 0.012, 0.979])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_and.train(X_and,y_and,max_iter=1000)\n",
    "p_and.predict(X_and)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the output Saying that for \n",
    "# (0,0) => (0) is the predicted value\n",
    "# (0,1) => (0.012 == 0 ) is predicted value which is too near to 0\n",
    "# (1,0) => (0.012 == 0 ) is predicted value which is too near to 0\n",
    "# (1,1) => (0.979 == 1 ) is predicted value which is too close to 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_or = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.int16)\n",
    "y_or = np.array([[0],[1],[1],[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_or = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.013, 0.994, 0.994, 1.   ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_or.train(X_or, y_or, max_iter=1000)\n",
    "p_or.predict(X_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the output Saying that for \n",
    "# (0,0) => (0.013 == 0 ) is the predicted value which is too near to 0\n",
    "# (0,1) => (0.994 == 1 ) is predicted value which is too near to 1\n",
    "# (1,0) => (0.994 == 1 ) is predicted value which is too near to 1\n",
    "# (1,1) => (1 == 1 ) is predicted value which is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
